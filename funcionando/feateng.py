# -*- coding: utf-8 -*-
"""feateng.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pAYXrQNYM5EBa4m9ucwW5HHj3Vl2-xpV

# 2nd part (feature engineering)
"""

# --- Importação das Bibliotecas ---
import pandas as pd
from pandas.api.types import is_numeric_dtype
import numpy as np
from tqdm.auto import tqdm
import holidays
from datetime import timedelta
import gc

# Inicializa o tqdm para uso com pandas
tqdm.pandas()

# --- PARÂMETROS E CONFIGURAÇÕES ---
# Adapte os nomes dos arquivos e as listas de colunas conforme seu projeto.
ARQUIVO_DADOS_SEMANAIS = 'prepared_weekly_data.parquet'
ARQUIVO_CADASTRO_PRODUTOS = 'cadastro_produtos.parquet'
ARQUIVO_CADASTRO_PDV = 'cadastro_pdv.parquet'
ARQUIVO_FINAL = 'feature_engineered_data.parquet'
COLUNAS_PRODUTOS_NECESSARIAS = ['produto', 'categoria', 'subcategoria', 'marca', 'fabricante']
COLUNAS_PDV_NECESSARIAS = ['pdv', 'zipcode', 'categoria_pdv', 'premise']


# --- FUNÇÃO DE OTIMIZAÇÃO DE MEMÓRIA (CORRIGIDA) ---
def reduce_mem_usage(df, name=''):
    """
    Reduz o uso de memória de um dataframe fazendo downcast de colunas numéricas.
    CORREÇÃO: Agora identifica e ignora corretamente colunas não-numéricas (como datas).
    """
    start_mem = df.memory_usage().sum() / 1024**2
    print(f'Uso de memória do dataframe "{name}": {start_mem:.2f} MB')

    for col in tqdm(df.columns, desc=f"Otimizando memória de {name}"):
        col_type = df[col].dtype

        # CORREÇÃO: A condição agora checa se a coluna é numérica antes de prosseguir.
        if is_numeric_dtype(col_type):
            c_min = df[col].min()
            c_max = df[col].max()

            # Trata inteiros
            if str(col_type)[:3] == 'int':
                if df[col].isnull().any():
                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                        df[col] = df[col].astype('Int8')
                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                        df[col] = df[col].astype('Int16')
                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                        df[col] = df[col].astype('Int32')
                    else:
                        df[col] = df[col].astype('Int64')
                else:
                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                        df[col] = df[col].astype(np.int8)
                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                        df[col] = df[col].astype(np.int16)
                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                        df[col] = df[col].astype(np.int32)
                    else:
                        df[col] = df[col].astype(np.int64)
            # Trata floats
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)

    end_mem = df.memory_usage().sum() / 1024**2
    print(f'Uso de memória final de "{name}": {end_mem:.2f} MB (Redução de {100 * (start_mem - end_mem) / start_mem:.1f}%)')
    return df

# --- INÍCIO DO SCRIPT ---

# --- Carregamento dos Dados Otimizado ---
print("--- Carregando dados... ---")
df = pd.read_parquet(ARQUIVO_DADOS_SEMANAIS)
df = reduce_mem_usage(df, 'dados semanais')

cadastro_produtos = pd.read_parquet(ARQUIVO_CADASTRO_PRODUTOS, columns=COLUNAS_PRODUTOS_NECESSARIAS)
cadastro_produtos = reduce_mem_usage(cadastro_produtos, 'cadastro de produtos')

cadastro_pdv = pd.read_parquet(ARQUIVO_CADASTRO_PDV, columns=COLUNAS_PDV_NECESSARIAS)
cadastro_pdv = reduce_mem_usage(cadastro_pdv, 'cadastro de PDV')


# --- 1. Features de Tempo (Vetorizado) ---
print("\n--- 1. Criando features de tempo... ---")
df['year'] = df['week_start'].dt.year
df['month'] = df['week_start'].dt.month
df['quarter'] = df['week_start'].dt.quarter
df['month_week'] = (df['week_start'].dt.day - 1) // 7 + 1

conditions = [
    (df['month'] >= 12) | (df['month'] <= 2),
    (df['month'] >= 3) & (df['month'] <= 5),
    (df['month'] >= 6) & (df['month'] <= 8),
    (df['month'] >= 9) & (df['month'] <= 11)
]
seasons = ['Verao', 'Outono', 'Inverno', 'Primavera']
df['season'] = np.select(conditions, seasons, default='Unknown')

br_holidays = holidays.Brazil(years=df['year'].unique())
all_dates = pd.to_datetime(pd.Series(df['week_start'].unique())).dt.date
holiday_weeks = {d for d in all_dates for i in range(7) if (d + timedelta(days=i)) in br_holidays}
df['is_holiday_week'] = df['week_start'].dt.date.isin(holiday_weeks).astype(int)

# --- 2. Features de Produto ---
print("\n--- 2. Criando features de produto... ---")
df = pd.merge(df, cadastro_produtos, on='produto', how='left')
del cadastro_produtos; gc.collect()

product_metrics = df.groupby('produto').agg(
    total_net_value=('net_value', 'sum'),
    total_qty_sold=('quantity', 'sum'),
    avg_weekly_qty=('quantity', 'mean'),
).reset_index()

product_metrics['avg_price'] = (product_metrics['total_net_value'] / product_metrics['total_qty_sold']).fillna(0)
price_percentiles = product_metrics['avg_price'].quantile([0.25, 0.5, 0.75]).values
product_metrics['price_tier'] = pd.cut(product_metrics['avg_price'], bins=[-np.inf] + list(price_percentiles) + [np.inf], labels=['Budget', 'Value', 'Premium', 'Luxury'])
qty_percentiles = product_metrics['total_qty_sold'].quantile([0.25, 0.5, 0.75]).values
product_metrics['popularity_tier'] = pd.cut(product_metrics['total_qty_sold'], bins=[-np.inf] + list(qty_percentiles) + [np.inf], labels=['Low', 'Medium', 'High', 'Very High'])

df = pd.merge(df, product_metrics.drop(columns=['total_net_value']), on='produto', how='left')
del product_metrics; gc.collect()

# --- 3. Features de PDV (Otimizado para RAM) ---
print("\n--- 3. Criando features de PDV (com otimização de RAM)... ---")
df = pd.merge(df, cadastro_pdv, on='pdv', how='left')
del cadastro_pdv; gc.collect()

df['pdv_total_sales'] = df.groupby('pdv')['quantity'].transform('sum')
df['pdv_avg_weekly_sales'] = df.groupby('pdv')['quantity'].transform('mean')
df['pdv_unique_products'] = df.groupby('pdv')['produto'].transform('nunique')

pdv_sales_agg = df[['pdv', 'pdv_total_sales']].drop_duplicates().set_index('pdv')
sales_percentiles = pdv_sales_agg['pdv_total_sales'].quantile([0.25, 0.5, 0.75]).values
pdv_sales_agg['pdv_size_tier'] = pd.cut(pdv_sales_agg['pdv_total_sales'], bins=[-np.inf] + list(sales_percentiles) + [np.inf], labels=['Small', 'Medium', 'Large', 'Very Large'])
df['pdv_size_tier'] = df['pdv'].map(pdv_sales_agg['pdv_size_tier'])
del pdv_sales_agg; gc.collect()

# --- 4. Features de Interação PDV-Produto ---
print("\n--- 4. Criando features de interação PDV-Produto... ---")
pair_metrics = df.groupby(['pdv', 'produto']).agg(
    pair_total_sales=('quantity', 'sum'),
    pair_avg_weekly_sales=('quantity', 'mean'),
    pair_sales_variability=('quantity', 'std')
).reset_index().fillna(0)

pair_metrics = pd.merge(pair_metrics, df[['pdv', 'pdv_total_sales']].drop_duplicates(), on='pdv', how='left')
pair_metrics['product_importance_to_pdv'] = (pair_metrics['pair_total_sales'] / pair_metrics['pdv_total_sales']).fillna(0)
df = pd.merge(df, pair_metrics.drop(columns=['pdv_total_sales']), on=['pdv', 'produto'], how='left')
del pair_metrics; gc.collect()

# --- 5. Features Avançadas de Séries Temporais ---
print("\n--- 5. Criando features avançadas de séries temporais... ---")
df = df.sort_values(['pdv', 'produto', 'week_start']).reset_index(drop=True)

df['qty_rolling_mean_4w'] = df.groupby(['pdv', 'produto'])['quantity'].transform(lambda x: x.rolling(4, min_periods=1).mean())
df['trend_4w'] = (df['quantity'] / df['qty_rolling_mean_4w'] - 1).replace([np.inf, -np.inf], 0).fillna(0)
df['month_lag_qty'] = df.groupby(['pdv', 'produto'])['quantity'].shift(4).fillna(0)

# --- 7. Codificação de Categóricas e Finalização ---
print("\n--- 7. Codificando colunas categóricas... ---")
cat_columns = [
    'season', 'price_tier', 'popularity_tier', 'pdv_size_tier',
    'categoria_pdv', 'premise', 'categoria', 'subcategoria', 'marca', 'fabricante'
]
for col in tqdm(cat_columns, desc="Codificando features"):
    if col in df.columns:
        df[col] = df[col].astype(str).astype('category').cat.codes

print("\n--- Otimizando uso final de memória... ---")
df = reduce_mem_usage(df, 'dataframe final')

print(f"\n--- Salvando dados em {ARQUIVO_FINAL}... ---")
df.to_parquet(ARQUIVO_FINAL, index=False)

print("\nEngenharia de features concluída com sucesso!")